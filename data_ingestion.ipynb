{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bc1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import gc\n",
    "import pandas as pd\n",
    "from utilities import *\n",
    "from config import *\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "print(\"Spacy model loaded\")\n",
    "\n",
    "def ner_title_extract_orgs(title): \n",
    "    doc = nlp(title)\n",
    "    return [ent.text.lower() for ent in doc.ents if ent.label_ == 'ORG']\n",
    "\n",
    "base_dir = os.getcwd()+'/data'\n",
    "all_items = os.listdir(base_dir)\n",
    "folders_only = [item for item in all_items if os.path.isdir(os.path.join(base_dir, item))]\n",
    "year_string, month_string, day_string = time.strftime('%Y/%m/%d').split('/')\n",
    "\n",
    "variables = GetEnvironmentVariables()\n",
    "openai.api_key = variables[\"OPENAI_API_KEY\"]\n",
    "print(\"OpenAI API key loaded\")\n",
    "\n",
    "distilled_student_sentiment_classifier = pipeline(\n",
    "    model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "    top_k=None\n",
    ")\n",
    "print(\"Distilled student sentiment classifier loaded\")\n",
    "\n",
    "print(\"reading all_stock_symbols.csv\")\n",
    "all_symbols = pd.read_csv('data/all_stock_symbols.csv')\n",
    "\n",
    "for folder in folders_only:\n",
    "    for str in ['hot', 'top']:\n",
    "        s_file = f\"{base_dir}/{folder}/{str}/year={year_string}/month={month_string}/day={day_string}/posts.csv\"\n",
    "        c_file = f\"{base_dir}/{folder}/{str}/year={year_string}/month={month_string}/day={day_string}/comments.csv\"\n",
    "        u_file = f\"{base_dir}/{folder}/{str}/year={year_string}/month={month_string}/day={day_string}/sentiment.csv\"\n",
    "\n",
    "        if os.path.exists(u_file):\n",
    "            print(f\"sentiment file already exists: {u_file}\")\n",
    "            continue\n",
    "\n",
    "        print(\"stocks file = \", s_file)\n",
    "        print(\"comments file = \", c_file)\n",
    "        print(\"sentiment file = \", u_file)\n",
    "        print(\"--------------------------------creating sentiment file for: \", folder, \" --------------------------------\")\n",
    "\n",
    "        stocks_posts = pd.read_csv(s_file)\n",
    "        stocks_comments = pd.read_csv(c_file)\n",
    "\n",
    "        print(\"enriching dataframe with AI and NLP\")\n",
    "        stocks_posts.drop(columns=['url', 'subreddit', 'author'], inplace=True)\n",
    "        stocks_posts['matching_symbols'] = stocks_posts['title'].apply(lambda x: find_stock_symbols_in_title(x, all_symbols['Symbol']))\n",
    "        stocks_posts['matching_orgs_spacy'] = stocks_posts['title'].apply(lambda x: ner_title_extract_orgs(x))\n",
    "        stocks_posts['matching_symbols_ai'] = stocks_posts['title'].apply(lambda x: query_openai_api(x, variables[\"OPENAI_API_KEY\"]))\n",
    "        stocks_posts['matching_orgs_nltk'] = stocks_posts['title'].apply(lambda x: nltk_extract_symbols(x))\n",
    "        stocks_posts['final_symbols'] = stocks_posts.apply(lambda row: extract_symbols_from_df_row(row, all_symbols), axis=1)\n",
    "        verify_posts_and_comments_unique(stocks_posts, stocks_comments)\n",
    "\n",
    "        print(\"Getting sentiment score\")\n",
    "        stocks_posts['pos_neu_neg'] = stocks_posts.apply(lambda row: get_sentiment_score(row, stocks_comments, distilled_student_sentiment_classifier), axis=1)\n",
    "        verify_posts_and_comments_unique(stocks_posts, stocks_comments)\n",
    "\n",
    "        stocks_posts.head(10)\n",
    "\n",
    "        symb_sent = stocks_posts[['final_symbols', 'pos_neu_neg']]\n",
    "\n",
    "        counter = {}\n",
    "        counter['total'] = {'counter': 0,\n",
    "                    'pos_tag': 0,\n",
    "                    'neu_tag': 0,\n",
    "                    'neg_tag': 0}\n",
    "\n",
    "        for _, row in symb_sent.iterrows():\n",
    "        # Skip None or NaN values\n",
    "            counter['total']['counter'] += 1\n",
    "            counter['total']['pos_tag'] += row['pos_neu_neg'][0]\n",
    "            counter['total']['neu_tag'] += row['pos_neu_neg'][1]\n",
    "            counter['total']['neg_tag'] += row['pos_neu_neg'][2]\n",
    "\n",
    "            if len(row['final_symbols']) <= 3:\n",
    "                for symbol in row['final_symbols']:\n",
    "                    if symbol not in counter:\n",
    "                        counter[symbol] = {\"counter\": 1,\n",
    "                                        'pos_tag': row['pos_neu_neg'][0],\n",
    "                                        'neu_tag': row['pos_neu_neg'][1],\n",
    "                                        'neg_tag': row['pos_neu_neg'][2]\n",
    "                                        }\n",
    "                    else:\n",
    "                        counter[symbol]['counter'] += 1\n",
    "                        counter[symbol]['pos_tag'] += row['pos_neu_neg'][0]\n",
    "                        counter[symbol]['neu_tag'] += row['pos_neu_neg'][1]\n",
    "                        counter[symbol]['neg_tag'] += row['pos_neu_neg'][2]\n",
    "\n",
    "        df = pd.DataFrame(counter)\n",
    "        df_t = df.transpose()\n",
    "        df_t.sort_values(by='counter', ascending=False, inplace=True)\n",
    "\n",
    "        print(\"df_t.to_csv(u_file, index=True)\")\n",
    "        df_t.to_csv(u_file, index=True)\n",
    "\n",
    "        print(\"deleting dataframes\")\n",
    "        del [stocks_posts, stocks_comments, symb_sent, counter, df, df_t]\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for folder in folders_only:\n",
    "    for str in ['hot', 'top']:\n",
    "        u_file = f\"{base_dir}/{folder}/{str}/year={year_string}/month={month_string}/day={day_string}/sentiment.csv\"\n",
    "        print(u_file)\n",
    "\n",
    "        if os.path.exists(u_file):\n",
    "            df = pd.read_csv(u_file)\n",
    "            dfs.append(df)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc9796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "   df.rename(columns={ df.columns[0]: \"symbol\" }, inplace = True)\n",
    "\n",
    "combined_df = pd.concat(dfs).groupby('symbol', as_index=False).sum()\n",
    "combined_df.sort_values(by='pos_tag', ascending=False, inplace=True)\n",
    "combined_df.to_csv(f'data/combined_df_year={year_string}_month={month_string}_day={day_string}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
